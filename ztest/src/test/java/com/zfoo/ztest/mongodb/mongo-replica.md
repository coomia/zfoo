复制集实现了数据库的数据同步，故障转移，读写分离

一个复制集最少应该包含三个节点，其中有一个必须是主节点。

数据同步：从节点会从主节点同步oplog到自己的节点，oplog有自己的大小，可以通过--oplogSize来设置。主从之间的读写对程序员是透明的。
故障转移（容灾）：主从节点两秒钟就会有一个心跳，如果发现主节点挂了就从新选取主节点，选取规则是从节点中最新的权重最高的节点；如果从节点挂了就直接选取从节点，再将主节点的数据同步给从节点。
读写分离：可以设置是优先从主节点读数据，还是优先从从节点读数据。
注：在单个节点中，数据先被写到内存，操作被保存在内存的视图中，内存视图没100ms写到硬盘的journal日志中，mongodb没60s将内存中的数据同步到硬盘。  


分片实现了数据的分布式存储，负载均衡，这些都是海量数据的云存储平台不可或缺的功能


分片集群中的一个片shard实际上就是一个复制集 


mongos路由进程是一个轻量级且非持久性的进程。轻量级表示它不会保存任何数据库中的数据，它只是将整个分片集群看成一个整体，使分片集群对整个客户端程序来说是透明的。  
当客户端发起读写操作时，由mongos路由进程将该操作路由到具体的片上进行；为了实现对读写请求的路由，mongos进程必须知道整个分片集群上所有数据库的分片情况，即元信息。  
这些信息是从配置服务器上同步过来的，每次进程启动时都会从configure服务器上读取信息，mongos并非持久化保存这些信息。  


配置服务器configure在整个分片集群中相当重要。上面说到mongos会从配置服务器同步元信息，因此配置服务器要能实现这些元信息的持久化。
配置服务器上的数据如果丢失，那么整个分片集群就无法使用，因此在生产环境中通常利用三台配置服务器来实现冗余备份，这三台服务器是独立的，并不是复制集架构 

 
集群dump备份恢复策略，对集群的备份就可以转化为对各复制集的备份：
1. 禁用平衡器，命令：sh.stopBalancer()；因为分片集群上会有一个balancer进程在后台维护各个片上数据块数量的均衡，如果不禁用平衡器可能会导致备份数据的重复或缺失   
2. 停止毎个片（复制集）上的某个secondary节点，利用此节点进行备份；停止其中某个配置服务器（所有配置服务器的数据一样)，保证备份时配务器上元数据不会改变，备份可以当作一单节点的实例  
3. 重启所有停掉的复制集成员，它们会自动从primary节点上的oplog同步数据，最终数据会达到一致性   
4. 重启分片集群的平衡器。通过mongo连接到mongos上，执行命令如下。use config；sh.startBalancer()


集群恢复流程：
1. 停止集群上的所有mongod实例和mongos实例。    
2. 利用上面备份的dump文件，依次恢复片中的每个复制集  
3. 恢复配置服务器。  
4. 重启所有mongod实例与mongos实例。  
5. 通过mongo连接上mongos，执行以下命令确保集群是可操作的：db.printShardingStatus() 